# -*- coding: utf-8 -*-
"""Departamento de Recursos Humanos - Pedro Ivo Mathias da Cruz Domingues Pereira

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B7hS7MMKTtnlev3w573zMI8DKdSej-n5

# Departamento de Recursos Humanos

## Importação das bibliotecas e base de dados

- Base de dados: https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset

Realizando a imporação das bibliotecas necessárias para o inicio do projeto que tem a finalidade de prever se um funcionário deixara a empresa não.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from keras.utils import to_categorical
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from google.colab import drive

"""Acessando o driver para pegar a base de dados necessária para realizar o treinamento"""

drive.mount('/content/drive')
empregado_df = pd.read_csv('/content/drive/MyDrive/IA/Human_Resources.csv')

"""## Visualização de dados

Exibindo a base de dados coletada na linha acima.
"""

empregado_df

"""Descrevendo os campos da base coletada."""

empregado_df.describe()

"""Verificando se existem dados Null para serem tratados."""

empregado_df.isnull()

empregado_df.isnull().sum()

"""Criando os gráficos com os dados das tabelas para ver a correlação entre eles."""

empregado_df.hist(figsize=(20,20))
plt.show()

corr = empregado_df.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corr, annot=True, cmap='coolwarm')

"""Verificando os tipos de dados presentes na base para tratar utilizando o OneHoteEncode."""

print(empregado_df.dtypes)

"""## Pré-processamento e bases de treinamento/teste

Realizando a substituição dos valores 'Yes' e 'No' para 1 e 0 respectivamente para facilitar na hora da previsao.
"""

empregado_df['Attrition'] = empregado_df['Attrition'].replace({'Yes' : 1,'No' : 0})

"""Expecificando as colunas categóricas (object) presente na base de dados."""

colunas_categoricas = ['BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']

"""Aplicando a técnica OneHotEnconding nas colunas separadas utilizando o get_dummies do pandas para representar variáveis categóricas como variáveis numéricas binárias."""

codificado = pd.get_dummies(empregado_df, columns = colunas_categoricas)

"""Verificando se os dados foram realmente tratados"""

print(codificado.dtypes)

"""Etapa de treinamento

Separando a coluna "importante" dos dados.
"""

X = codificado.drop('Attrition', axis=1)
y = codificado['Attrition']

"""Dividindo os dados em treinamento e teste."""

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)

"""Normalização dos dados"""

scaler = MinMaxScaler()

X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)

"""##Criando a estrutura da rede

Arquitetura

Iniciando o modelo de rede neuroal sequencial como vazio
"""

rede_neural = tf.keras.models.Sequential()

"""Preenchendo o modelo de rede com 3 camadas densas, onde a primeira camada tem ativação relu utilizando 20 neurônios e com o número de inputs igual ao numero de colunas do meu X_train, logo abaixo utiliznado um dropout com 0.5 para evitar o overfitting durante o treinamento.

Novamente na linha abaixo adicionando uma nova camada densa relu com 8 neurônios e utilizando dropout.

na ultima linha adicionando uma camada densa de ativação sigmoid com 1 neurônio.
"""

rede_neural.add(tf.keras.layers.Dense(activation='relu',units=20 ,input_shape=(X_train.shape[1],)))
rede_neural.add(tf.keras.layers.Dropout(0.5))

rede_neural.add(tf.keras.layers.Dense(activation='relu',units = 8))
rede_neural.add(tf.keras.layers.Dropout(0.5))

rede_neural.add(tf.keras.layers.Dense(activation = 'sigmoid',units=1))

"""Compilando a rede neural, definindo o otimizador como adam, a função de perda como binary_crossentropy e vakudação como accuracy.

O adam é um método de otimização usado para treinar redes neurais que adapta a taxa de aprendizagem ao longo do treinamento.

O binary_crossentropy é uma função de perda usada para problemas de classificação binária.

A métrica de avaliação 'accuracy' é usada para avaliar a precisão do modelo em prever a classe correta. Ela é calculada como a proporção de previsões corretas em relação ao número total de exemplos.
"""

rede_neural.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])

"""Treinando a rede neural MLP com os dados de treinamento gerados acima."""

rede_neural.fit(X_train, y_train, epochs=200, batch_size=20,validation_data=(X_test, y_test))

"""##Acuracia treinamento e teste."""

accuracy = rede_neural.evaluate(X_test, y_test)
print('Accuracy total do treinamento:', accuracy)

accuracy2 = rede_neural.evaluate(X_train, y_train)
print('Accuracy total do treinamento:', accuracy2)

"""## Redes neurais artificiais

- Quantos neurônios e quantas camadas? https://iaexpert.academy/2020/05/04/quantas-camadas-escondidas-e-quantos-neuronios-incluir-numa-rede-neural-artificial/

- import tensorflow as tf
- rede_neural = tf.keras.models.Sequential()
- rede_neural.add(tf.keras.layers.Dense()

## Salvar o classificador
"""

import pickle

# Salvar o modelo treinado em disco
with open('modelo_treinado.pkl', 'wb') as arquivo:
    pickle.dump(rede_neural, arquivo)

"""##Aplicação Web"""

!pip install streamlit

import streamlit as st
import pandas as pd
import pickle

# Carregando o modelo treinado
model = pickle.load(open('modelo_treinado.pkl', 'rb'))

# Título da página
st.title('Departamento de Recursos Humanos')

# Descrição do problema
st.markdown('Aplicação referente a possibilidade de o funcionário deixar ou não a empresa.')

# Criação do formulário
with st.form(key='employee_form'):
    # Criando as colunas do formulário
    col1, col2 = st.beta_columns(2)

    # Adicionando os campos ao formulário
    with col1:
        monthly_income = st.number_input('Renda Mensal (R$):', min_value=0)
        total_working_years = st.number_input('Total de Anos Trabalhados:', min_value=0)
        years_at_company = st.number_input('Anos na Empresa:', min_value=0)
        years_in_current_role = st.number_input('Anos na Posição Atual:', min_value=0)

    with col2:
        job_level = st.selectbox('Nível do Cargo:', ['1', '2', '3', '4', '5'])
        job_involvement = st.selectbox('Envolvimento com o Trabalho:', ['1', '2', '3', '4'])
        job_satisfaction = st.selectbox('Satisfação com o Trabalho:', ['1', '2', '3', '4'])
        stock_option_level = st.selectbox('Nível de Opções de Ações:', ['0', '1', '2', '3'])

    # Adicionando os campos de Business Travel, Job Role, Marital Status e OverTime
    business_travel = st.selectbox('Frequência de Viagens a Negócios:', ['Travel_Rarely', 'Travel_Frequently', 'Non-Travel'])
    job_role = st.selectbox('Cargo:', ['Sales Executive', 'Research Scientist', 'Laboratory Technician', 'Manufacturing Director', 'Healthcare Representative', 'Manager', 'Sales Representative', 'Research Director', 'Human Resources'])
    marital_status = st.selectbox('Estado Civil:', ['Married', 'Single', 'Divorced'])
    over_time = st.selectbox('Trabalha Horas Extras?', ['Yes', 'No'])

    # Botão para submeter os dados
    submit_button = st.form_submit_button(label='Prever')